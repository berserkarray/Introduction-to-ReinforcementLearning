{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhmzy9URkRdo"
   },
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NaWm6LjxkRds",
    "outputId": "a3fb721e-e1ca-42fb-9e82-031b00c37429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package xvfb.\n",
      "(Reading database ... 160706 files and directories currently installed.)\n",
      "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
      "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
      "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Starting virtual X frame buffer: Xvfb.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "6uuIgcookRdt",
    "outputId": "ec1a1f68-9309-4d55-843f-586244844955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDYl9R33kRdu"
   },
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fn9mU8OkRdu",
    "outputId": "6d3468df-d8c8-426b-eee9-aaa25955e77b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "gz1BlKN5kRdv"
   },
   "outputs": [],
   "source": [
    "def generate_session(env, agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        s = s.reshape(1, -1)\n",
    "        probs = agent.predict_proba(s)\n",
    "        probs = probs.reshape(env.action_space.n)\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(range(0, env.action_space.n), p = probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "        \n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPPTkqkrkRdw",
    "outputId": "d0ac28f5-fc3d-418d-e4a1-0c52238f647e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[[-0.02523579  0.04958071 -0.04273847  0.03263496]]\n",
      "\n",
      " [[-0.02424417 -0.14490312 -0.04208577  0.31153303]]\n",
      "\n",
      " [[-0.02714223  0.05079236 -0.03585511  0.00588017]]\n",
      "\n",
      " [[-0.02612639  0.24640969 -0.03573751 -0.29789637]]\n",
      "\n",
      " [[-0.02119819  0.44202237 -0.04169543 -0.60163263]]]\n",
      "actions: [0, 1, 1, 1, 1]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiF4Cu7ZkRdx"
   },
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "OJzUkAj5kRdx"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    elite_states = np.array([])\n",
    "    elite_actions = np.array([])\n",
    "\n",
    "    rewards_threshold = np.percentile(rewards_batch, percentile)\n",
    "    rewards = rewards_batch >= rewards_threshold\n",
    "    \n",
    "    for i in range(0, len(rewards_batch)):\n",
    "      if rewards[i]:\n",
    "        elite_states = np.append(elite_states, states_batch[i])\n",
    "        elite_actions = np.append(elite_actions, actions_batch[i])\n",
    "        \n",
    "    elite_states = np.squeeze(elite_states)\n",
    "    \n",
    "    elite_states = np.reshape(elite_states, (-1, 4))\n",
    "    elite_actions = np.reshape(elite_actions, -1)\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2kjMm5ckRdy"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S7DyUQBskRdz"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "IW3bXbA0kRd0",
    "outputId": "35f36083-b680-499e-e989-187c05208547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 286.930, threshold=339.600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-082706eef038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mstates_batch_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mstates_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_batch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mactions_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_batch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-b4ce5d85b2ba>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"make sure probabilities are a vector (hint: np.reshape)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_from_c_func_and_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "  states_batch = []\n",
    "  actions_batch = []\n",
    "  rewards_batch = []\n",
    "  for i in range(0, n_sessions):\n",
    "      states_batch_t, actions_batch_t, rewards_batch_t = generate_session(env, agent, 1000)\n",
    "      states_batch.append(states_batch_t)\n",
    "      actions_batch.append(actions_batch_t)\n",
    "      rewards_batch.append(rewards_batch_t) \n",
    "\n",
    "    #states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "  elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "  agent.partial_fit(elite_states, elite_actions)\n",
    "  show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "  if np.mean(rewards_batch) > 190:\n",
    "      print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd-mmVvjkRd0"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "01Xaibd5kRd1"
   },
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501,
     "resources": {
      "http://localhost:8080/videos/openaigym.video.0.64.video000064.mp4": {
       "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
       "headers": [
        [
         "content-length",
         "1449"
        ],
        [
         "content-type",
         "text/html; charset=utf-8"
        ]
       ],
       "ok": false,
       "status": 404,
       "status_text": ""
      }
     }
    },
    "id": "mUpku9DwkRd1",
    "outputId": "20754437-47af-4f4b-c327-a8741c488786"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.64.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUVLVKkrkRd2"
   },
   "source": [
    "## Assignment: MountainCar\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "_if you have any trouble with CartPole-v0 and feel stuck, take a look at the forums_\n",
    "\n",
    "Your assignment is to obtain average reward of __at least -150__ on `MountainCar-v0`.\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "  \n",
    "* Bonus quest: Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "mMMb7R2hkRd2",
    "outputId": "b4905124-6588-4387-ea99-73316ed8c847"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-0f4c2f10cf28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MountainCar-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mvisualize_mountain_car\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_mountain_car\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'agent_mountain_car' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    # Compute policy for all possible x and v (with discretization)\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    \n",
    "    grid = np.dstack(np.meshgrid(xs, vs[::-1])).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3).transpose(1, 0, 2)\n",
    "\n",
    "    # # The above code is equivalent to the following:\n",
    "    # probs = np.empty((len(vs), len(xs), 3))\n",
    "    # for i, v in enumerate(vs[::-1]):\n",
    "    #     for j, x in enumerate(xs):\n",
    "    #         probs[i, j, :] = agent.predict_proba([[x, v]])[0]\n",
    "\n",
    "    # Draw policy\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.imshow(probs, extent=(env.min_position, env.max_position, -env.max_speed, env.max_speed), aspect='auto')\n",
    "    ax.set_title('Learned policy: red=left, green=nothing, blue=right')\n",
    "    ax.set_xlabel('position (x)')\n",
    "    ax.set_ylabel('velocity (v)')\n",
    "    \n",
    "    # Sample a trajectory and draw it\n",
    "    states, actions, _ = generate_session(env, agent)\n",
    "    states = np.array(states)\n",
    "    ax.plot(states[:, 0], states[:, 1], color='white')\n",
    "    \n",
    "    # Draw every 3rd action from the trajectory\n",
    "    for (x, v), a in zip(states[::3], actions[::3]):\n",
    "        if a == 0:\n",
    "            plt.arrow(x, v, -0.1, 0, color='white', head_length=0.02)\n",
    "        elif a == 2:\n",
    "            plt.arrow(x, v, 0.1, 0, color='white', head_length=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "HbuFSkNwkRd4"
   },
   "outputs": [],
   "source": [
    "# Implement generate_session_mountain_car(), training loop, etc.\n",
    "env = gym.make(\"MountainCar-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "car_agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(40, 20),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "car_agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))\n",
    "\n",
    "def generate_session_mountain_car(env, car_agent, t_max=10000):\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        s = s.reshape(1, -1)\n",
    "        probs = car_agent.predict_proba(s)\n",
    "        probs = probs.reshape(env.action_space.n)\n",
    "        assert probs.shape == (env.action_space.n,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(range(0, env.action_space.n), p = probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "        \n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return states, actions, total_reward\n",
    "\n",
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    elite_states = np.array([])\n",
    "    elite_actions = np.array([])\n",
    "\n",
    "    rewards_threshold = np.percentile(rewards_batch, percentile)\n",
    "    rewards = rewards_batch >= rewards_threshold\n",
    "    \n",
    "    for i in range(0, len(rewards_batch)):\n",
    "      if rewards[i]:\n",
    "        elite_states = np.append(elite_states, states_batch[i])\n",
    "        elite_actions = np.append(elite_actions, actions_batch[i])\n",
    "        \n",
    "    elite_states = np.squeeze(elite_states)\n",
    "    \n",
    "    elite_states = np.reshape(elite_states, (-1, 2))\n",
    "    elite_actions = np.reshape(elite_actions, -1)\n",
    "    return elite_states, elite_actions\n",
    "\n",
    "n_sessions = 100\n",
    "percentile = 90\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "  states_batch = []\n",
    "  actions_batch = []\n",
    "  rewards_batch = []\n",
    "  for i in range(0, n_sessions):\n",
    "      states_batch_t, actions_batch_t, rewards_batch_t = generate_session(env, car_agent, 10000)\n",
    "      states_batch.append(states_batch_t)\n",
    "      actions_batch.append(actions_batch_t)\n",
    "      rewards_batch.append(rewards_batch_t) \n",
    "\n",
    "    #states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "  elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "  car_agent.partial_fit(elite_states, elite_actions)\n",
    "  \n",
    "\n",
    "#<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cic80jzUkRd4"
   },
   "source": [
    "### Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dalyOoHrkRd5"
   },
   "outputs": [],
   "source": [
    "from submit import submit_mountain_car\n",
    "submit_mountain_car(generate_session_mountain_car, car_agent, 'sohams20@iitk.ac.in', 'hBsFPdr3B7xVnq0V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0gKg6PF2BbA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "deep_crossentropy_method.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
